{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2745: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1299: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "path's length : 80, start : 141, end : 142\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_node (LSTM)            (1, 128)                  73728     \n",
      "_________________________________________________________________\n",
      "output_node (Dense)          (1, 276)                  35604     \n",
      "=================================================================\n",
      "Total params: 109,332\n",
      "Trainable params: 109,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1's path epochs : 0\n",
      "Epoch 1/1\n",
      "0s - loss: 15.4484 - acc: 0.0395\n",
      "64/76 [========================>.....] - ETA: 0sacc: 3.95%\n"
     ]
    }
   ],
   "source": [
    "# 0. 사용할 패키지 불러오기\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Input, Embedding\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "import csv\n",
    "import random\n",
    "\n",
    "# 랜덤시드 고정시키기\n",
    "np.random.seed(5)\n",
    "   \n",
    "MAX_IDX = 275\n",
    "MAX_GRID = 275\n",
    "FEATURE_NUM = 15\n",
    "TOTAL_DATA = MAX_GRID * MAX_IDX\n",
    "WINDOW_SIZE = 4  #TODO :: edit\n",
    "\n",
    "# 손실 이력 클래스 정의\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def init(self):\n",
    "        self.losses = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "\n",
    "# 그리드에서 랜덤으로 값 받아오는 함수\n",
    "def randomPickInGrid(Wdata, Max, GridNum):\n",
    "    randidx = random.randrange(0,Max * 0.8)\n",
    "    return Wdata[int((GridNum-1)*Max*0.8) + randidx]\n",
    "\n",
    "# 경로 입력하면 데이터 만들어서 넣어주는 함수\n",
    "def genData(Wdata, path):\n",
    "    path_len = len(path)\n",
    "    real_val = []\n",
    "    for i in range(path_len):\n",
    "        real_val.append(randomPickInGrid(Wdata,MAX_IDX,path[i]))\n",
    "#         real_val[i][FEATURE_NUM] = int(real_val[i][FEATURE_NUM]) - 1 # 경로가 1부터 있어서 one-hot-encoding 하면 +1됨 \n",
    "                                                                     # 따라서 -1 붙여준다\n",
    "    return real_val\n",
    "\n",
    "# WINDOW_SIZE에 맞게 데이터 잘라주는 함수\n",
    "def makeWindowMat(seqData):\n",
    "    dataset_x = []\n",
    "    dataset_y = []\n",
    "    for i in range(len(seqData) - WINDOW_SIZE):\n",
    "        subset = seqData[i : ( i + WINDOW_SIZE + 1)]\n",
    "        for si in range(len(subset) - 1):\n",
    "            dataset_x.append(subset[si][:FEATURE_NUM])\n",
    "        dataset_y.append(subset[WINDOW_SIZE][FEATURE_NUM:])\n",
    "    return np.array(dataset_x) , np.array(dataset_y)\n",
    "\n",
    "class CustomHistory(keras.callbacks.Callback):\n",
    "    def init(self):\n",
    "        self.losses = []\n",
    "        self.vol_losses = []\n",
    "        self.accs = []\n",
    "        self.vol_accs = []        \n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.vol_losses.append(logs.get('vol_loss'))\n",
    "        self.accs.append(logs.get('acc'))\n",
    "        self.vol_accs.append(logs.get('acc_loss'))\n",
    "\n",
    "# WiFi 데이터 불러오기\n",
    "f = open('./data/made_wifi4.csv', 'r', encoding='utf-8')\n",
    "rdr = csv.reader(f)\n",
    "\n",
    "WiFiData = []\n",
    "for line in rdr:\n",
    "    tmp = []\n",
    "    for i in range(FEATURE_NUM):\n",
    "        tmp.append((line[i]))\n",
    "    tmp.append(int(line[FEATURE_NUM]))\n",
    "    WiFiData.append(tmp)\n",
    "f.close()\n",
    "\n",
    "# 4. 모델 학습과정 설정하기\n",
    "early_stop = EarlyStopping(monitor='loss', patience=5) # 조기종료\n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model('wifi_LSTM_model4.h5')\n",
    "temp_weights = [layer.get_weights() for layer in model.layers]\n",
    "\n",
    "# print(temp_weights)\n",
    "\n",
    "# Define the model\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "\n",
    "model.add(LSTM(128, batch_input_shape = (1, 4, 15), stateful=True, name = \"input_node\"))\n",
    "# model.add(LSTM(128, input_shape = (WINDOW_SIZE, FEATURE_NUM), stateful=False)) # stateless 테스트용\n",
    "model.add(Dense(275 + 1, activation='softmax', name = \"output_node\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "for i in range(len(temp_weights)):\n",
    "    model.layers[i].set_weights(temp_weights[i])\n",
    "    \n",
    "# 1. 데이터 준비하기\n",
    "f = open('path4.csv', 'r', encoding='utf-8-sig')\n",
    "rdr = csv.reader(f)\n",
    "\n",
    "path_idx = 0\n",
    "path_choice = [1] ## 학습 할 path만 설정\n",
    "\n",
    "for line in rdr:\n",
    "    tmp = []\n",
    "    path_idx += 1\n",
    "    if path_idx not in path_choice: ## 중간에 몇개의 path만 실행한다\n",
    "        continue\n",
    "    for i in range(len(line)):\n",
    "        tmp.append(int(line[i]))\n",
    "    path = tmp\n",
    "    print(\"path's length : \" + str(len(path)) + \", start : \" + str(path[0]) + \", end : \" + str(path[len(path)-1]))\n",
    "\n",
    "    # 5. 모델 학습시키기\n",
    "    num_epochs = 1\n",
    "\n",
    "    history = LossHistory() # 손실 이력 객체 생성\n",
    "    history.init()\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    custom_hist = CustomHistory()\n",
    "    custom_hist.init()\n",
    "    \n",
    "    for epoch_idx in range(num_epochs):\n",
    "        trainData = genData(WiFiData,path)\n",
    "        x_train, y_train = makeWindowMat(trainData)\n",
    "        x_train = np.reshape(x_train, (len(path) - WINDOW_SIZE, WINDOW_SIZE, FEATURE_NUM))\n",
    "        y_train = np_utils.to_categorical(y_train, num_classes=276)\n",
    "        one_hot_vec_size = y_train.shape[1]\n",
    "        print (str(path_idx) + \"'s path epochs : \" + str(epoch_idx) )\n",
    "        tb_hist = keras.callbacks.TensorBoard(log_dir='./graph2', histogram_freq=0, write_graph=True, write_images=True)\n",
    "        model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2, shuffle=False, callbacks=[tb_hist]) # 50 is X.shape[0]\n",
    "        model.reset_states()\n",
    "\n",
    "    # stateless Test한거임\n",
    "    # model.fit(x_train,y_train, epochs= 2000, batch_size=4, verbose = 1)\n",
    "\n",
    "    # 6. 학습과정 살펴보기\n",
    "#     %matplotlib inline\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     plt.plot(history.losses)\n",
    "#     plt.ylabel('loss')\n",
    "#     plt.xlabel('epoch')\n",
    "#     plt.legend(['train'], loc='upper left')\n",
    "#     plt.show()\n",
    "\n",
    "    # 7. 모델 평가하기\n",
    "    scores = model.evaluate(x_train, y_train, batch_size=1)\n",
    "    print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "    model.reset_states()\n",
    "    \n",
    "f.close()\n",
    "\n",
    "# model.save('wifi_LSTM_model4.h5')\n",
    "## TODO:: 저장된 이후부터 모든 경로 학습하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
